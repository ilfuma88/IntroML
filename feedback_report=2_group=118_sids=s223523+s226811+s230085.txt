
-------------------------------------------------------------------------------------------------------------------------------
02450 Introduction to Machine Learning and Data Mining - 2023 Fall [12/06/2023, 15:32:32]


Feedback for report no.: 2
Group: 118
Student(s): Giovanni Orzalesi (s223523) & Miroslav Holecek (s226811) & Riccardo Conti (s230085)
Primary marker: Stas Syrota

Please validate the list of student ids on this feedback form to make sure it is correct and matches the group when 
you submitted report 2 (contact the course coordinator if there are issues with group membership/ids).

Note: The feedback is provided for individual group members; however, it will typically be identical for all members
unless the markers have found it necessary to differentiate the assessment and feedback.

-------------------------------------------------------------------------------------------------------------------------------
        
::::: Feedback for Giovanni Orzalesi (s223523) :::::: 
Overall:
The report is quite below acceptable level. Several sections are missing in the regression tasks and the discussion of classification contains misunderstandings. See more detail below:
Regression (a):
- Without seeing the features, it is difficult to see if your feature transformations are sensible. Did you include categorical variables? How were they encoded?
- Figures are good, in general. Your lambda range is way too wide. Looking at figure 1, one wants to see a bit more fine grained lambda selection between 10^0 and 10^4, not just every factor of 10. 
- Discussion of Figure 1 is ok, but the language should be more clear. In the context of modelling there is a huge difference between “influences” and “influenced”. The legend screenshot  is very useful but could be tidier.
- Missing a final linear regression equation or its form.
Regression (b):
- Your code suggests that you only do 1 level Cross Validation for the ANN, this is wrong.
- “Baseline Model: The baseline model simply calculates the mean of the values in the test set and uses this mean as an estimation for each input.” - This is very wrong. You should use the mean from the training set. This is equivalent to training a model on the test set. 
- It is unclear what range of lambda you use for the inner loop. Is it the same as in part (a) or is it narrower? Wider? (It should be narrower). 
- Statistical tests are missing
- Language should be more clear, same comment as to part (a). 
- A sensible discussion is missing
Classification:
- Statistical tests are quite lacking/show misunderstandings. You claim to use setup (II), ie. Method 11.4.1. But this is very problematic. First, you are comparing classifiers, which renders the t-test in setup (I) invalid. In setup (II) you assume that the errors are Normally distributed and in the box, it says that the test set should AT LEAST contain 30 values. I am not sure, but it seems (from the report) that the total number of observations is around 25? Some reflection around this should find place in the discussion. Since it is not there, it points towards a misunderstanding. The correct thing to do in this case is to use setup (I) ie. Method 11.3.2: The McNemar test for comparing classifiers. 
- Equation (3) shows misunderstanding. Your beta_1 is a vector of betas. You then try to compare the coefficients with the linear regression case. This is ok, but you are supposed to discuss whether the coefficients are interpretable in a sensible way.
Discussion:
The discussion is fuzzy and is built on claims that you did not verify in the regression (b) part, for instance. The fuzzyness is around treating regression of PH value and classification of potability as equivalent.

-------------------------------------------------------------------------------------------------------------------------------
        
::::: Feedback for Miroslav Holecek (s226811) :::::: 
Overall:
The report is quite below acceptable level. Several sections are missing in the regression tasks and the discussion of classification contains misunderstandings. See more detail below:
Regression (a):
- Without seeing the features, it is difficult to see if your feature transformations are sensible. Did you include categorical variables? How were they encoded?
- Figures are good, in general. Your lambda range is way too wide. Looking at figure 1, one wants to see a bit more fine grained lambda selection between 10^0 and 10^4, not just every factor of 10. 
- Discussion of Figure 1 is ok, but the language should be more clear. In the context of modelling there is a huge difference between “influences” and “influenced”. The legend screenshot  is very useful but could be tidier.
- Missing a final linear regression equation or its form.
Regression (b):
- Your code suggests that you only do 1 level Cross Validation for the ANN, this is wrong.
- “Baseline Model: The baseline model simply calculates the mean of the values in the test set and uses this mean as an estimation for each input.” - This is very wrong. You should use the mean from the training set. This is equivalent to training a model on the test set. 
- It is unclear what range of lambda you use for the inner loop. Is it the same as in part (a) or is it narrower? Wider? (It should be narrower). 
- Statistical tests are missing
- Language should be more clear, same comment as to part (a). 
- A sensible discussion is missing
Classification:
- Statistical tests are quite lacking/show misunderstandings. You claim to use setup (II), ie. Method 11.4.1. But this is very problematic. First, you are comparing classifiers, which renders the t-test in setup (I) invalid. In setup (II) you assume that the errors are Normally distributed and in the box, it says that the test set should AT LEAST contain 30 values. I am not sure, but it seems (from the report) that the total number of observations is around 25? Some reflection around this should find place in the discussion. Since it is not there, it points towards a misunderstanding. The correct thing to do in this case is to use setup (I) ie. Method 11.3.2: The McNemar test for comparing classifiers. 
- Equation (3) shows misunderstanding. Your beta_1 is a vector of betas. You then try to compare the coefficients with the linear regression case. This is ok, but you are supposed to discuss whether the coefficients are interpretable in a sensible way.
Discussion:
The discussion is fuzzy and is built on claims that you did not verify in the regression (b) part, for instance. The fuzzyness is around treating regression of PH value and classification of potability as equivalent.

-------------------------------------------------------------------------------------------------------------------------------
        
::::: Feedback for Riccardo Conti (s230085) :::::: 
Overall:
The report is quite below acceptable level. Several sections are missing in the regression tasks and the discussion of classification contains misunderstandings. See more detail below:
Regression (a):
- Without seeing the features, it is difficult to see if your feature transformations are sensible. Did you include categorical variables? How were they encoded?
- Figures are good, in general. Your lambda range is way too wide. Looking at figure 1, one wants to see a bit more fine grained lambda selection between 10^0 and 10^4, not just every factor of 10. 
- Discussion of Figure 1 is ok, but the language should be more clear. In the context of modelling there is a huge difference between “influences” and “influenced”. The legend screenshot  is very useful but could be tidier.
- Missing a final linear regression equation or its form.
Regression (b):
- Your code suggests that you only do 1 level Cross Validation for the ANN, this is wrong.
- “Baseline Model: The baseline model simply calculates the mean of the values in the test set and uses this mean as an estimation for each input.” - This is very wrong. You should use the mean from the training set. This is equivalent to training a model on the test set. 
- It is unclear what range of lambda you use for the inner loop. Is it the same as in part (a) or is it narrower? Wider? (It should be narrower). 
- Statistical tests are missing
- Language should be more clear, same comment as to part (a). 
- A sensible discussion is missing
Classification:
- Statistical tests are quite lacking/show misunderstandings. You claim to use setup (II), ie. Method 11.4.1. But this is very problematic. First, you are comparing classifiers, which renders the t-test in setup (I) invalid. In setup (II) you assume that the errors are Normally distributed and in the box, it says that the test set should AT LEAST contain 30 values. I am not sure, but it seems (from the report) that the total number of observations is around 25? Some reflection around this should find place in the discussion. Since it is not there, it points towards a misunderstanding. The correct thing to do in this case is to use setup (I) ie. Method 11.3.2: The McNemar test for comparing classifiers. 
- Equation (3) shows misunderstanding. Your beta_1 is a vector of betas. You then try to compare the coefficients with the linear regression case. This is ok, but you are supposed to discuss whether the coefficients are interpretable in a sensible way.
Discussion:
The discussion is fuzzy and is built on claims that you did not verify in the regression (b) part, for instance. The fuzzyness is around treating regression of PH value and classification of potability as equivalent.

-------------------------------------------------------------------------------------------------------------------------------
        